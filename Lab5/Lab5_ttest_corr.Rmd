```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE}
suppressWarnings(library(tidyverse))
```

## Статистика вывода

Построение выводов о свойствах популяции (генеральной совокупности) на
основе анализа случайных выборок.

0.  Гипотеза исследования
1.  Нулевая и альтернативная гипотеза
2.  Подсчет статистики по выборке
3.  Расчет p-value
4.  Принятие решения

**1. Формулирование нулевой и альтернативной гипотезы.**

Пример: Средняя длина предложений у носителей и изучающих язык.

$$H_1: \mu_1 \ne \mu_2$$

Нулевая гипотеза:

$$H_0: \mu_1 = \mu_2$$

Гипотеза $H_1$ называется также альтернативной. NB $H_1$ и $H_0$
касаются популяции, а не конкретной выборки.

Тестирование нулевой гипотезы предполагает подсчет какой-то статистики,
а потом вычисление того, какова вероятность получить такой или более
радикальный результат при условии, что верна нулевая гипотеза.

Другие варианты альтернативной и нулевой гипотезы $$H_1: \mu_1 > \mu_2$$
$$H_0: \mu_1 = \mu_2$$ или:

$$H_1: \mu_ < \mu_2$$ $$H_0: \mu_1 = \mu_2$$ Начнем с еще более простого
случая, когда у нас есть только одна группа:

$$H_1: \mu \ne 100$$ $$H_0: \mu = 100$$

**2. Подсчет тестовой статистики по выборке**

Задача: сравнить полученное значение статистики в тесте с другими
*возможными* значениями, которые мы могли бы получить, если бы наша
нулевая гипотеза была верна.

Пример: z-статистика на основе z-распределения. Если мы знаем среднее и
стандартное отклонение в генеральной совокупности, то можем посчитать
$z$-статистику по формуле:

$$z = \frac{\overline{x} - \mu} {\sigma / \sqrt{N}} $$ $z$-статистика
--- это выборочное среднее, из которого вычтено среднее в генеральной
совокупносности согласно нашей гипотезе. Получившуюся разницу мы делим
на стандартную ошибку.

```{r}
set.seed(42)
samp <- rnorm(100, mean = 100, sd = 15)
m <- mean(samp)
sem <- 15/sqrt(length(samp))
z <- (m - 100)/sem
z
```

**3. Расчет p-value**

p-value -- это вероятность получить такую и более отклоняющуюся тестовую
статистику при условии, что $H_0$ верна.

Вернемся к идее выборочных распределений, только теперь уже не среднего,
а $z$-статистики. Благодаря тому, что мы вычли среднее и поделили на
стандартное отклонение, среднее этого нормального распределения будет
равно 0, а стандартное отклонение -- 1.

Благодаря ЦПТ, даже если распределение в генеральной совокупности
несколько отличается от нормального, а выборка достаточно большая, то
выборочное распределение $z$-статистик при верности нулевой гипотезы
будет (примерно) нормальным.

Соотнесем нашу $z$-статистику с теоретическим выборочным распределением
$z$-статистик. Какова вероятность получить такой же или более радикально
отличающийся результат при допущении верности нулевой гипотезы, т.е.
какова p-value?

![](images/explanationsPValue.png){width="400"}

Если $z$-статистика отрицательная, то считаем от минус бесконечности до
$z$-статистики.

Другой способ - воспользуемся функцией накопленной плотности
распределения `pnorm()`:

```{r}
pnorm(z)
```

`pnorm()` считает от минус бесконечности до заданного числа, поэтому для
z\>0 вычтем площадь из единицы.

```{r}
1 - pnorm(z)
# or
pnorm(z, lower.tail=FALSE)
```

Теперь это число нужно умножить на 2, потому что мы заранее не знаем, в
какую сторону будет отклоняться среднее по нашей выборке.

$$H_1: \mu_1 = 100$$

Это означает, что $H_1$ включает в себя как случаи, когда среднее
отклоняется в большую сторону, так и случаи когда среднее отклоняется в
меньшую сторону.

```{r}
p <- (1 - pnorm(z))*2
p
```

Это число и есть **p-value** --- вероятность получения такого же и более
экстремального значения тестовой статистики при условии, что нулевая
гипотеза верна.

**4. Принятие решения о гипотезах**

Насколько маленьким должен быть *p-value*, чтобы отклонить нулевую
гипотезу? **Критическое значение *p-value*, при котором отклоняют
нулевую гипотезу, называется уровнем** $\alpha$. Это максимальный
уровень ошибки, который мы допускаем в исследовании.

Стандартный уровень $\alpha$ в научной литературе 0.05. Но это
условность, и есть рекомендации считать $\alpha=0.01$ в отдельных
отраслях и при определенных дизайнах исследования.

| Принятое решение Реальность | $H_0$ верна                  | $H_1$ верна                   |
|------------------------|------------------------|------------------------|
| Не отклоняем $H_0$          | Верный пропуск               | Ошибка 2 рода (type II error) |
| Отклоняем $H_0$             | Ошибка 1 рода (type I error) | Верное попадание              |

Если $H_0$ на самом деле верна, а мы ее отвергли и приняли $H_1$, то это
**ошибка первого рода** (*type I error*). Вероятность этой ошибки и есть
наше критическое значение $\alpha$. Однако есть вероятность ошибиться и
в другую сторону, т.е. ошибочно не отклонить $H_0$ --- это **ошибка
второго рода** (*type II error*), эта вероятность обозначается буквой
$\beta$.

# t-тест Уильяма Госсета

![](images/William_Gosset_plaque_in_Guinness_Ireland.jpg)

## Одновыборочный t-тест

Мы научились делать z-тест. Но на практике это обычно не так, так как мы
оцениваем стандартное отклонение в генеральной совокупности на основе
стандартного отклонения по выборке. Эта тестовая статистика уже не
распределена нормально, а распределена согласно t-распределению. Наша
статистика - t-статистика.

$$t = \frac{\overline{x} - \mu} {s_x / \sqrt{N}} $$

Форма этого распределения очень похожа на форму нормального
распределения, но имеет более тяжелые "хвосты" распределения. При этом
эта форма зависит от размера выборки: чем больше выборка, тем ближе
распределение к нормальному. Этот параметр распределения называется
**степенями свободы** *(degrees of freedom)* и вычисляется как $N - 1$,
где $N$ - это размер выборки.

```{r, echo=FALSE}
library(tidyverse)
t_normal_pdf_gg <- tibble(x = seq(-3, 3, .01),
       t_3 = dt(x, df = 3),
       t_10 = dt(x, df = 10),
       t_100 = dt(x, df = 100),
       normal = dnorm(x)) %>%
  pivot_longer(cols = -x, values_to = 'pdf', names_to = 'distribution') %>%
  ggplot(aes(x = x, y = pdf, colour = distribution))+
  geom_line()+
  theme_light()

t_normal_pdf_gg
```

Чем больше выборка (и количество степеней свободы, соответственно), тем ближе t-распределение к стандартному нормальному распределению. При 100 степенях свободы они уже почти не различимы!
Поэтому на больших выборках разница между t-тестом и z-тестом будет минимальна, тогда как на маленьких выборках разница может быть значительной.

Посчитаем t-статистику:

```{r}
set.seed(42)
samp <- rnorm(100, 100, 15)
m <- mean(samp)
sem <- sd(samp)/sqrt(length(samp))
t <- (m - 100)/sem
t
```

Сравним с z-статистикой:

```{r}
(m - 100) / (15/sqrt(100))
```

Как видите, расчет довольно схожий, разница только в том, откуда мы
берем стандартное отклонение. Для z-статистики у нас был заранее
известный параметр генеральной совокупности (что обычно не так), для
t-статистики мы оценивали стандартное отклонение по выборке.

Давайте теперь посчитаем p-value. Мы будем пользоваться не функцией
`pnorm()`, а функцией `pt()`, а в качестве параметра распределения
указать количество степеней свобод в `df =`

```{r}
pt(t, df = length(samp) - 1)
```

Функция `pt()` считает от минус бесконечности до $t$, а нам нужно от $t$
до плюс бесконечности, потому что $t$ больше 0:

```{r}
1 - pt(t, df = length(samp) - 1)
```

И не забываем умножать на 2, если мы хотим сделать двусторонний тест.

```{r}
(1 - pt(t, df = length(samp) - 1))*2
```

В отличие от z-теста, t-тест есть в базовом R.

```{r}
t.test(samp, mu = 100)
0.3122351
```

Здесь можно увидеть выборочное среднее как оценку среднего в генеральной
совокупности, 95% доверительный интервал для оценки среднего в
генеральной совокупности, t-статистику, степени свобод и p-value.

### Упражнение  

Возьмите датасет durationsOnt (Pluymaekers et al., 2005) из учебника Baayen 2008.
Получите описательные статистики по переменной DurationPrefixNasal, постройте гистограмму. 
Предположим, что предыдущие исследования показали, что средняя длительность этой переменной составляет 0.053. Верно ли, что среднее значение DurationPrefixNasal, полученное в данном эксперименте, значимо  отличается от 0.053?  
Используйте критическое значение статистической значимости в 5%. 

```{r}
# install.packages("languageR")
library(languageR)
data(durationsOnt)
summary(durationsOnt$DurationPrefixNasal) 
```

$H_1: mean(x) \ne 0.53$ 

$H_0: mean(x) = 0.53$ 

Можем ли мы отвергнуть нулевую гипотезу? 

t-тест показал, что мы можем отвергнуть нулевую гипотезу (t = -226.73, df = 101, p-value < 2.2e-16). Тем самым, среднее значение DurationPrefixNasal 0,05 статистически значимо отличается от 0.53. 

### Альтернативы

$H1: \mu1 > \mu_0$

```{r}
my_sample <- c(80, 90, 100, 100, 130)
mu0 <- 125
mean(my_sample)
t.test(my_sample, mu = mu0, alternative = 'less')
x <- seq(-2.9881, 5, 0.01)
curve(dt(t, df=4), from = -5, to=5, xname = 't')

# add shading
polygon(c(x[1], x, x[length(x)]), 
        c(0, dt(x, df=4), 0), col="steelblue")

x <- seq(-5, -2.9881, 0.01)
curve(dt(t, df=4), from = -5, to=5, xname='t')

# add shading
polygon(c(x[1], x, x[length(x)]), 
        c(0, dt(x, df=4), 0), col="steelblue")

```
p-value = 97%

## Двухвыборочный t-тест

Тест на сравнение средних двух выборок. 
$$H_0: \mu_1 = \mu_2$$
$$H_1: \mu_1 \ne \mu_2$$
## Зависимый и независимый t-test.

Зависимый - тест с повторными измерениями (или другими зависимостями, внутрииндивидуальный дизайн исследования).
Независимый - нельзя напрямую соотнести значения в двух выборках друг с
другом, более того, размер двух выборок может быть разным (межиндивидуальный дизайн исследования)

| Внутрииндивидуальный план | Межиндивидуальный план |
|---------------------------|------------------------|
| Зависимый t-тест          | Независимый t-тест     |


## Двухвыборочный зависимый t-тест 

Двухвыборочный зависимый t-тест --- это то же самое, что и
одновыборочный t-тест, только для разницы между связанными значениями.
Поскольку наша нулевая гипотеза звучит, что средние должны быть равны,

$$H_0: \mu_1 = \mu_2$$

то при верности нулевой гипотезы $$\mu_1 - \mu_2 = 0$$.

Тогда вместо $x$ подставим $d$ --- разницу (вектор разниц) между парами
значений. Получаем вот что:

$$t = \frac{\overline{x} - \mu} {s_x / \sqrt{N}} = \frac{\overline{d} - (\mu_1 - \mu_2)} {s_d / \sqrt{N}} = \frac{\overline{d} - 0} {s_d / \sqrt{N}}  = \frac{\overline{d}} {s_d / \sqrt{N}}$$
Мы будем использовать [данные с курса по статистике Университета
Шеффилда про эффективность
диет](https://www.sheffield.ac.uk/polopoly_fs/1.570199!/file/stcp-Rdataset-Diet.csv).
Возьмем данные по диете номер 1 и посмотрим, действительно ли
она помогает сбросить вес.

```{r}
library(tidyverse)
diet <- readr::read_csv("https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/stcp-Rdataset-Diet.csv")
diet1 <- diet %>%
  filter(Diet == 1)
```

Провести двухвыборочный t-тест можно в R двумя базовыми способами.
Первый вариант - это дать два вектора значений. Это удобно в случае
широкого формата данных.

```{r}
t.test(diet1$pre.weight, diet1$weight6weeks, paired = TRUE)
```

Второй вариант - используя формулы. Это удобно при длинном формате
данных:

```{r}
diet1_long <- diet1 %>%
  pivot_longer(
  cols = c(pre.weight, weight6weeks),
  names_to = "when",
  values_to = "weight"
  )
  

t.test(weight ~ when, data = diet1_long)
t.test(diet1_long$weight ~ diet1_long$when)
```

В обоих вариантах мы использовали `paired = TRUE` , чтобы обозначить
использование именно зависимого (т.е. парного) t-теста.

| Внутрииндивидуальный план    | Межиндивидуальный план        |
|------------------------------|-------------------------------|
| Зависимый t-тест             | Независимый t-тест            |
| `t.test(..., paired = TRUE)` | `t.test(..., paired = FALSE)` |


## Двухвыборочный независимый t-тест

В случае независимого t-теста формула отличается. Однако гипотеза
остается такой же и логика примерна та же.

У двух выборок могут различаться стандартные отклонения, поэтому для
подсчет стандартной ошибки разницы средних для независимых выборок нужно
сначала посчитать **объединенное стандартное отклонение (pooled standard
deviation)**:

$$s^2_{pool} = \frac {(n_1-1)s^2_1 + (n_2-1)s^2_2} {(n_1 - 1) + (n_2 -1)}$$

Тогда стандартная ошибка разницы средних считается следующим образом:

$$se_{m_1 - m_2} = \sqrt {(s^2_{pool}) (\frac {1} {n_1} + \frac {1}{n_2} )}$$

Выглядит сложно, но по своей сути это что-то вроде усредненного
стандартного отклонения (с учетом размеров выборок). Ну а t-статистика
затем считается просто:

$$t = \frac {(m_1 - m_2) - (\mu_1 - \mu_2)} {se_{m_1 - m_2}} = \frac {(m_1 - m_2) - 0} {se_{m_1 - m_2}} = \frac {m_1 - m_2} {se_{m_1 - m_2}}$$

Давайте теперь опробуем независимый t-тест для сравнения веса испытуемых
двух групп после диеты. Мы снова воспользуемся функцией `t.test()`, но
теперь уже поставим `paired = FALSE`:

```{r}
diet12 <- diet %>%
  filter(Diet %in% 1:2)
t.test(weight6weeks ~ Diet, data = diet12)
```

Степени свободы в результатах теста дробные! Дело в том, что мы провели не совсем "настоящий"
t-тест, а его очень близкую альтернативу под названием **тест Уэлча**
*(Welch test)*, который иногда называют **поправкой Уэлча** к t-тесту.
Эта поправка позволяет тесту лучше справляться с выборками с разной
дисперсией. Даже если у нас нет проблем с разной дисперсией, то от
поправки Уэлча хуже не будет, поэтому это вариант по умолчанию в R.

Но если его хочется отключить, то нужно поставить `var.equal = TRUE`.

```{r}
t.test(weight6weeks ~ Diet, data = diet12, var.equal = TRUE)
```


### Допущения t-теста 

Чтобы подсчет *p-value* был корректным, некоторые допущения должны быть
выполнены.

1.  **Непрерывные** **Нормальное распределение** 
Если размер выборки больше 28 (30, 50), то обычно игнорируют.

тест Шапиро-Уилка на нормальность распределения:

```{r}
shapiro.test(samp)
```
или проверять визуально с помощью гистограммы или Q-Q plot. 

2.  Для двувыборочного независимого t-теста выборки должны быть взяты из
    распределения **с одинаковыми дисперсиями**. Однако это не так
    критично с применением поправки Уэлча.

3.  **Независимость значений (или пар)** в выборке. Типичным примером
    нарушения независимости является случай, когда t-тест применяется на
    неусредненных (например, по испытуемому) значениях. Еще один пример
    нарушения независимости --- использование одного наблюдения
    несколько раз или использование одного и того же испытуемого
    несколько раз. Определить независимость можно следующим мысленным
    экспериментом: могу ли я хоть как-нибудь предсказать следующее
    значение в выборке? Например, в случае с несколькими значениями от
    одного испытуемого я могу ориентироваться на его предыдущие
    результаты и предсказать последующие результаты лучше, чем на основе
    простого среднего по всем остальным значениям. Это значит, что
    допущение о независимости нарушено.

### Упражнение

"Vowel duration and aspiration effects in Icelandic”, Stefano Coretta, University of York, 2016 [link](https://osf.io/6au2k/). В диссертации тестируется ряд гипотез:  
Voicing effect: vowels are longer than followed by voiced consonants;    
Aspiration effect: vowels followed by pre-aspirated (geminate) stops are shorter than vowels followed by unaspirated (geminate) stops.  

Есть ли статистически значимая разница между round and unrounded times?
Есть ли статистически значимая разница между vowel.dur и roundness times? 
$H_0: mean(round\_times) = mean(unrounded\_times)$
$H_1: mean(round\_times) \ne mean(unrounded\_times)$ 

```{r}
library("tidyverse")
dat <- read.csv("https://bit.ly/39Fr0gD")
dat %>% slice_head(n=4)

ggplot(data = dat, aes(x = vowel.dur, y = roundness)) +
  geom_boxplot(notch=TRUE) + # CI around the median +/- 1.58*IQR/sqrt(n)
  theme_minimal()

round_times <- dat %>%
  filter(roundness == "round") %>%
  select(time)
round_times %>% count()

unrounded_times <- dat %>%
  filter(roundness == "unrounded") %>%
  select(time)
unrounded_times %>% count()

t.test(round_times, unrounded_times, paired = FALSE)
```
p-value = 0.3359 = 33% [0,1]
$\alpha = 5%$
p-value > 5%
==> не можем отвергнуть нулевую гипотезу 

Согласно t-критерию Стьюдента (t = -0.9631, df = 589.36, p-value = 0.3359) нельзя отвергнуть нулевую гипотезу. Статистически значимой разницы между средними не найдено. Наши данные не дают возможности утверждать, что разница есть.
Между долготой гласного, вероятно, нет разницы


## Непараметрические аналоги t-теста 

Если выборка не очень большая и взята из сильно ассиметричного
распределения или выборка представляет собой порядковые данные, то можно
воспользоваться непараметрическими альтернативами для t-теста.

Непараметрические тесты не имеют допущений о распределении, что делает
их более универсальными. Большинство подобных тестов подразумевает
превращение данных в ранги, т.е. внутри этих тестов происходит
преобразование в ранговую шкалу. Такое преобразование может снизить
статистическую мощность теста и привести к повышению вероятности ошибки
второго рода.

### Тест Уилкоксона {#sec-wilcox_test}

Непараметрический аналог двустороннего *зависимого* t-теста называется
**тестом Уилкоксона.** Функция для него называется `wilcox.test()`, и
она имеет такой же синтаксис, как и `t.test()`.

```{r}
wilcox.test(weight ~ when, data = diet1_long)
```

> Cообщение *"Есть совпадающие значения: не могу высчитать точное p-значение"* означает, что в ваших данных есть повторяющиеся значения, поэтому расчет p-value в данном случае --- это некоторая апроксимация. В большинстве случаев это сообщение можно игнорировать.

### Тест Манна-Уитни 

Непараметрическим аналогом двустороннего *независимого* t-теста является
**тест Манна-Уитни.** Для него тоже используется функция
`wilcox.test()`, только в данном случае с параметром `paired = FALSE`.

```{r}
wilcox.test(weight ~ when, data = diet1_long)
```

| Внутрииндивидуальный план         | Межиндивидуальный план             |
|-----------------------------------|------------------------------------|
| Зависимый t-тест:                 | Независимый t-тест:                |
| `t.test(..., paired = TRUE)`      | `t.test(..., paired = FALSE)`      |
| Тест Уилкоксона:                  | Тест Манна-Уитни:                  |
| `wilcox.test(..., paired = TRUE)` | `wilcox.test(..., paired = FALSE)` |


## Корреляция (Correlation) 

Сначала - **ковариация** (co-variation). 
- положительная ковариация: чем *больше* одна переменная, тем *больше* другая переменная. 
- отрицательная ковариация: чем *больше* одна переменная, тем *меньше* другая.

```{r}
x <- c(1, 2, 6, 8, 9, 7, 7.5, 10, 3, 4, 5.5)
y <- c(2, 4, 11, 15, 19, 16, 14, 23, 7, 6, 11)
plot(x, y)
```

- формула ковариации: 
$$\sigma_{xy} = cov(x, y) = \frac{\sum_{i = 1}^n(x_i - \overline{x})(y_i - \overline{y})}{n}$$

- Оценка ковариации по выборке:

$$\hat{\sigma}_{xy} = \frac{\sum_{i = 1}^n(x_i - \overline{x})(y_i - \overline{y})}{n-1}$$
Дисперсия - ковариация переменной самой с собой.

```{r covariation matrix}
cov(x, y)
var(x, y) # функция дисперсии при двух переменных считает то же самое 
```

Значение ковариации привязано к исходной шкале данных. Много или мало - трудно сказать. 

Корреляция - как сама связь между переменными, так и способ ее измерить. 

## Коэффициенты корреляции Пирсона и Спирмена/Кенделла 
(Pearson's coefficient vs Spearman's and Kendall's coefficients) 

* Коэффициент Пирсона - для непрерывных данных  
* Принимает значение от -1 (отрицательная корреляция) до 1 (положительная корреляция)  
* Нормированная ковариация (ковариация, нормированная на стандартное отклонение обеих переменных)   
* Можно понимать как среднее произведение z-scores   
* условие для Пирсона -- примерно нормальное распределение переменных  
* Коэффициент Пирсона чувствителен к выбросам  
* Коэффициент Спирмена/Кенделла - для шкальных или непрерывных данных (шкала Ликерта, доли и т.д.)  
* условие для Спирмена -- парные измерения (количество точек x и у совпадает)  
* желательное условие для Спирмена/Кенделла -- монотонная связь между переменными   
* не ловит нелинейную связь  


$$\rho_{xy} = \frac{\sigma_{xy}}{\sigma_x \sigma_y} = \frac{\sum_{i = 1}^n(x_i - \overline{x})(y_i - \overline{y})}{\sqrt{\sum_{i = 1}^n(x_i - \overline{x})^2}\sqrt{\sum_{i = 1}^n(y_i - \overline{y})^2}} = \frac{1}{n}\sum_{i = 1}^n z_{x,i} z_{y, i}$$

Оценка коэффициента корреляции Пирсона по выборке: 
$$r_{xy} = \frac{\hat{\sigma}_{xy}}{\hat{\sigma}_x \hat{\sigma}_y} = \frac{\sum_{i = 1}^n(x_i - \overline{x})(y_i - \overline{y})}{\sqrt{\sum_{i = 1}^n(x_i - \overline{x})^2}\sqrt{\sum_{i = 1}^n(y_i - \overline{y})^2}} = \frac{1}{n - 1}\sum_{i = 1}^n z_{x,i} z_{y, i}$$
```{r}
# Pearson's correlation
cor(x, y)
```

Корреляция положительная и сильная (почти равна 1). 

Статистическая значимость корреляции (например, при $\alpha$ = 0.05). 

* Какую нулевую гипотезу мы тестируем? 

```{r}
# Pearson's coefficient
cor.test(x, y)
```
$H_o$ - отсутствие корреляции в генеральной совокупности 
$$H_0: (\rho_{xy} = 0)$$
Если переменных не две, а больше? 

```{r}
#install.packages("Stat2Data")
library(Stat2Data)
library(psych)
data(Backpack)
Backpack %>%
  mutate(backpack_kg = 0.45359237 * BackpackWeight,
         body_kg = 0.45359237 * BodyWeight) %>%
  select(body_kg, backpack_kg, Units, Year) %>%
#cor()  
#  psych::corr.test()
#  psych::corr.test(adjust = "bonferroni")
  psych::corr.test(adjust = "BH")
```

#### Проблема множественных сравнений

* поправка Бонферрони (Bonferroni correction)
 - умножение p-value на количество гипотез  
* поправка Холма или поправка Холма-Бонферрони (Holm-Bonferroni correction)
* поправка Бенджамини-Хохберга (BH, Benjamini-Hochberg correction) как контроль False Discovery Rate (FDR, средняя доля ложных отклонений при заданной $\alpha$, например, доля FDR меньше 5%) 

```{r}
library(corrplot)
cor(mtcars)
```

Основная функция пакета `{corrplot}` -- функция `corrplot()`. Давайте теперь попробуем ее применить на нашей матрице корреляций.

```{r}
corrplot(cor(mtcars))
```

По умолчанию значение корреляций кодируется цветом и размером круга. У функции `corrplot()` есть множество параметров, позволяющих довольно тонко настраивать хитмэп корреляций. Например, можнокодировать только цветом, а переменные сгруппировать на основе кластеризации.

```{r}
corrplot(cor(mtcars), method = "color", order = "hclust")
```

Или так: [source](https://www.r-bloggers.com/spearman-correlation-heat-map-with-correlation-coefficients-and-significance-levels-in-r/)

```{r, message=FALSE}
suppressMessages(library(Hmisc))
suppressMessages(library(reshape2))
cormatrix <- rcorr(as.matrix(mtcars), type='spearman')
cormatrix
str(cormatrix)
cordata <- melt(cormatrix$r)
ggplot(cordata, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile() + xlab("") + ylab("")
```

### Коэффициенты корреляции Спирмена и Кендалла

Коэффициент корреляции Спирмена использует формулу Пирсона, но вместо абсолютных значений используются (частотные) ранги значений. 

```{r}
x = c(277,169,157,139,108,213,232,229,114,232,161,149,128)
y = c(256,118,137,144,146,221,184,188,97,231,114,187,230)
rx = rank(x)
# rx = {13, 8, 6, 4, 1, 9, 11.5, 10,  2, 11.5,  7,  5,  3}
ry = rank(y)
mx = mean(rx)
my = mean(ry)
sum((rx-mx)*(ry-my))/sqrt(sum((rx-mx)^2)*sum((ry-my)^2))
# 0.5144434
cor(rx,ry)
# 0.5144434

cor.test(x, y, method = 'spearman')
```

```{r}
cor.test(x, y, method = 'kendall') 
```

Если в данных есть совпадающие значения, тест Спирмена выдаст предупреждение "Cannot compute exact p-values with ties". В этом случае можно задать аргумент `exact=FALSE`, чтобы не видеть предупреждения, но проблемы это не решит. Особенно если размер выборки небольшой.  
Первый путь - задать для совпадающих значений промежуточные ранги (написать функцию или указать конкретный вектор). Другой путь -- использовать тест Кендалла с поправкой на ties:  

$$Kendall's   \tau_b = (P - Q) / ( (P + Q + Y_0)*(P + Q + X_0) )^{0.5}$$

, где  
$P$: количество согласующихся пар (ранги в паре либо оба увеличиваются, либо оба убывают)  
$Q$: количество несогласующихся пар  
$X_0$: количество пар x с неповторяющимися значениями (not tied on x)  
$Y_0$: количество пар y с неповторяющимися значениями (not tied on y)  

```{r}
cor.test(x,y, method = 'spearman')
cor.test(rx,ry) # Pearson on ranks is Spearman  
rx = c(13, 8, 6, 4, 1, 9, 11.45, 10,  2, 11.5,  7,  5,  3) # ranks corrected manually 
cor.test(rx,ry) # Pearson on non-averaged (non-tied) ranks is Spearman-no-ties  
```
Итак, методы Спирмена и Кендалла почти во всех случаях взаимозаменимы, но коэффициент Спирмена будет сильнее штрафовать сильную несогласованность в рангах (см. сумму квадратов в знаменателе), в то время как коэффицент Кендалла оценивает их более линейно.  

### Как отчитаться о проведенном тесте  

```
С целью определить связь между <переменной А> и <переменной Б> был проведен корреляционный анализ Пирсона/Спирмена/Кендалла. Найдена статистически значимая сильная положительная корреляция между <переменной А> и <переменной Б> (r/ρ/τ = .535, p = .003, df=8, n=10).
```


### Упражнение 

Для работы возьмите датасет по рассказам А. П. Чехова (`chekhov.csv`, [link](https://raw.githubusercontent.com/LingData2019/LingData2020/master/data/chekhov.csv)).

Переменные: 
* `n_words`: количество слов в рассказе 
* `n_unique`: количество уникальных слов в рассказе 

1. Каков ваш прогноз, есть ли линейная связь между количеством слов (= длиной текста) и количеством уникальных слов?

2. Постройте график рассеяния для этих переменных и проверьте вашу интуицию. Интерпретируйте данные на графике. 

3. Используйте подходящий статистический критерий для проверки гипотезы о связи между значениями переменных `n_words` и `n_unique`: сформулируйте нулевую гипотезу, протестируйте ее и сформулируйте выводы.

```{r}
chekhov <- read_csv("https://raw.githubusercontent.com/LingData2019/LingData2020/master/data/chekhov.csv") %>%
  dplyr::select(n_words, n_unique)
str(chekhov)
skimr::skim(chekhov)
# ggplot(chekhov, aes(...)) +
#  geom_point(alpha = 0.3)  

# Visual test for normality: 
suppressWarnings(library(DescTools))
PlotQQ(chekhov$n_unique)
```

### Misc

Графическая интерпретация коэффициента корреляции Пирсона -- соотношение точек в закрашенных и незакрашенных областях. 

```{r slide for lecture}
ggplot(chekhov, aes(n_words-1090.067, n_unique-616.200)) +
  geom_point() + 
  geom_vline(xintercept = 0, colour="#BA1825") +
  geom_hline(yintercept = 0, colour="#BA1825") +
  xlim(-1000, 1000) +
  ylim(-600,600) + 
  annotate('rect', xmin=1, xmax=1000, ymin=1, ymax=600, alpha=.2, fill='darkgreen') +
  annotate('rect', xmin=-1000, xmax=-1, ymin=-600, ymax=-1, alpha=.2, fill='darkgreen')

cor.test(chekhov$n_words,chekhov$n_unique)
```

Пример нелинейной зависимости и непараметрический корреляционный анализ:

```{r spirals}
golden.ratio = (sqrt(5) + 1)/2
fibonacci.angle=360/(golden.ratio^2)
c=1
num_points=630
x=rep(0,num_points)
y=rep(0,num_points)

for (n in 1:num_points) {
    r=c*sqrt(n)
    theta=fibonacci.angle*(n)
    x[n]=r*cos(theta)
    y[n]=r*sin(theta)
}
data.frame(x,y) %>%
ggplot(aes(x, y)) +
  geom_point()

cor.test(x, y, method = 'spearman')
cor.test(x, y, method = 'kendall')
```

